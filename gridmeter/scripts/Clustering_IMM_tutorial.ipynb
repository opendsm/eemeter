{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting starting with the GRIDmeterâ„¢ library\n",
    "\n",
    "This jupyter notebook is an interactive tutorial. It walks through loading data, running the stratified sampling model, and plotting results. You'll run all the code yourself. Cells can be executed with `<shift><enter>`. If you feel so inspired, make edits to the code in these cells and dig deeper.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background -- why this library\n",
    "\n",
    "The `gridmeter` library originated from a project lead by Recurve Analytics, Inc. and funded by the US Dept. of Energy designed to identify practical methods for analyzing energy efficiency which are robust to external shocks (e.g. COVID-19).  From June through September 2020, Recurve hosted a series of meetings with industry stakeholders to discuss methods for constructing comparison groups, with the goal of presenting a recommended standard method to the GRID working group, a subsidiary of the Linux Foundation for Energy.  During this time, Recurve developed Python software to implement stratified sampling and demonstrate its effectiveness in practice.  The `gridmeter` library is the open-source Apache-licensed output of this process and is available to be used by anyone. \n",
    "\n",
    "This notebook will take you through several things that this library can do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on tutorial scope and related libraries\n",
    "\n",
    "This tutorial assumes the reader has properly installed python and has a basic working knowledge of python syntax and usage. \n",
    "\n",
    "The `gridmeter` library uses `pandas` data frames as its principle way of representing data, therefore all inputs and outputs are data frames; see [this tutorial](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) for information on how to use `pandas`.  The `plotnine` library is used to make visualizations which can be embedded in a Jupyter notebook or saved as .pngs; see [this website](https://plotnine.readthedocs.io/en/stable/) for information on `plotnine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gridmeter as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing documentation\n",
    "\n",
    "You can view code documentation by appending a question mark to a function and then executing that code, as in the following example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "\n",
    "Typically one begins with two populations of meters: a **treatment group**, and a **comparison pool**.  The treatment group consists of those meters for which savings needs to be tracked, e.g. if they represent customers participating in an energy efficiency program.  The comparison pool consists of all of the available meters that are not part of the treatment group.  The goal is to select a **comparison group** which is a subset of the comparison pool, such that the control group is **similar** to the treatment group.  The comparison group will then provide a realistic counterfactual compared to the treatment group and can be used to accurately estimate the impact of a program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up data\n",
    "\n",
    "Gridmeter uses the `Data` class as the inputs to all of the comparison group methods. Its purpose is to validate your data and to perform the necessary transformations to go into the comparison group methods. `Data` is instantiated with `Data_Settings`. Once instantiated the method `.set_data` can be called using one of `loadshape_df` and `time_series_df` as well as `features_df` depending upon your needs. If you input `time_series_df` it will compute the loadshape.\n",
    "\n",
    "Method requirements:\n",
    "- Clustering: Loadshape\n",
    "- Individual Meter Matching: Loadshape\n",
    "- Stratified Sampling: Loadshape/Features (depends upon settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and assign data\n",
    "\n",
    "# data_type = \"month_loadshape\"\n",
    "# data_type = \"seasonal_day_of_week_loadshape\"\n",
    "data_type = \"seasonal_hourly_day_of_week_loadshape\"\n",
    "\n",
    "df_ls_all = gm.load_tutorial_data(data_type)\n",
    "\n",
    "# randomly select 100 ids from df_ls_all\n",
    "all_ids = df_ls_all.index.to_list()\n",
    "t_ids = np.random.choice(all_ids, 100, replace=False)\n",
    "\n",
    "df_ls_treatment = df_ls_all.loc[t_ids].reset_index()\n",
    "\n",
    "# remove t_ids from all_ids\n",
    "all_ids = [x for x in all_ids if x not in t_ids]\n",
    "cp_ids = np.random.choice(all_ids, 1000, replace=False)\n",
    "\n",
    "df_ls_pool = df_ls_all.loc[cp_ids].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data classes\n",
    "\n",
    "data_settings = gm.Data_Settings(AGG_TYPE=None, LOADSHAPE_TYPE=None, TIME_PERIOD=None)\n",
    "\n",
    "pool_data = gm.Data(data_settings)\n",
    "pool_data.set_data(loadshape_df=df_ls_pool)\n",
    "\n",
    "treatment_data = gm.Data(data_settings)\n",
    "treatment_data.set_data(loadshape_df=df_ls_treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Meter Matching\n",
    "For Euclidean distance matching, the usage patterns of each treatment meter are compared to the usage patterns of each comparison pool meter in order to find the closest matches. The subsequent group of meters that have been \"matched\" become the resulting comparison group.\n",
    "\n",
    "## Features For Matching\n",
    "\n",
    "Any usage pattern can be used for euclidean distance matching. If an 8760 hourly trace is available, it is suggested to use a 'seasonal-hour-of-week' load-shape (3 168-point load shapes, one for summer, winter, and shoulder). If only monthly data is available, it is suggested to use the 12 months of usage as the usage pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_settings = gm.IMM_Settings()\n",
    "imm = gm.IMM(imm_settings)\n",
    "df_cg, df_t_coeffs = imm.get_comparison_group(treatment_data, pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm.plot_loadshapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Clustering was developed to be used with model error, but in this example we'll be using observed loadshapes purely to demonstrate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_settings = gm.Clustering_Settings(USE_MULTIPROCESSING=True)\n",
    "clustering = gm.Clustering(clustering_settings)\n",
    "df_cg, df_t_coeffs = clustering.get_comparison_group(treatment_data, pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.plot_loadshapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial.  For questions, comments, or issues, please raise a Github issue here:  \n",
    "https://github.com/recurve-methods/comparison_groups/issues\n",
    "\n",
    "We thank you for your interest and participation in this project and look forward to your feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
